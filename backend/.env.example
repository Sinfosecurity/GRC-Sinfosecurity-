# Backend Environment Variables
# Copy this file to .env and update with your values

# ===========================
# Application Settings
# ===========================
NODE_ENV=development
PORT=4000
API_VERSION=v1

# DEV_MODE: Set to true to run without databases (uses mock data)
# Set to false for production with real databases
DEV_MODE=true

# ===========================
# CORS Settings
# ===========================
CORS_ORIGIN=http://localhost:3000

# ===========================
# Database - PostgreSQL (Primary)
# ===========================
# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE
# Example: postgresql://grc_user:grc_password@localhost:5432/grc_platform
DATABASE_URL="postgresql://grc_user:grc_password@localhost:5432/grc_platform"

# ===========================
# Database - MongoDB (Documents)
# ===========================
# Format: mongodb://USER:PASSWORD@HOST:PORT/DATABASE
# Example: mongodb://grc_user:grc_password@localhost:27017/grc_documents
MONGODB_URI="mongodb://grc_user:grc_password@localhost:27017/grc_documents"

# ===========================
# Database - Redis (Cache)
# ===========================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=grc_redis_password

# ===========================
# Database - Elasticsearch (Search)
# ===========================
ELASTICSEARCH_NODE=http://localhost:9200
ELASTICSEARCH_USERNAME=elastic
ELASTICSEARCH_PASSWORD=grc_elastic_password

# ===========================
# JWT Authentication
# ===========================
# Generate secure random strings for production:
# node -e "console.log(require('crypto').randomBytes(64).toString('hex'))"
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
JWT_REFRESH_SECRET=your-super-secret-refresh-key-change-this-in-production

# Token expiration times
JWT_EXPIRES_IN=15m
JWT_REFRESH_EXPIRES_IN=7d

# ===========================
# Email Configuration (Optional)
# ===========================
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@example.com
SMTP_PASSWORD=your-email-password
SMTP_FROM=GRC Platform <noreply@sinfosecurity.com>

# ===========================
# File Upload Settings
# ===========================
MAX_FILE_SIZE=10485760
UPLOAD_DIR=./uploads

# ===========================
# Rate Limiting
# ===========================
# Auth endpoints: requests per time window
AUTH_RATE_LIMIT_WINDOW_MS=900000
AUTH_RATE_LIMIT_MAX_REQUESTS=5

# General API: requests per time window
API_RATE_LIMIT_WINDOW_MS=900000
API_RATE_LIMIT_MAX_REQUESTS=100

# ===========================
# Logging
# ===========================
LOG_LEVEL=info
LOG_FILE_ERROR=./logs/error.log
LOG_FILE_COMBINED=./logs/combined.log

# ===========================
# AI Service Integration
# ===========================
AI_SERVICE_URL=http://localhost:5000
AI_SERVICE_ENABLED=true

# ===========================
# Production Settings (Only for production)
# ===========================
# HTTPS Settings
# SSL_KEY_PATH=/path/to/ssl/key.pem
# SSL_CERT_PATH=/path/to/ssl/cert.pem

# Security
# SESSION_SECRET=your-session-secret-for-production
# COOKIE_SECURE=true
# COOKIE_HTTP_ONLY=true
# COOKIE_SAME_SITE=strict

# ===========================
# Development Settings
# ===========================
# Set to true for detailed error messages
DEBUG=true
# ============================================
# MONITORING & OBSERVABILITY
# ============================================

# --- Metrics Collection ---
METRICS_ENABLED=true
METRICS_PORT=4000
METRICS_PATH=/metrics
METRICS_COLLECTION_INTERVAL=15000  # 15 seconds

# --- Sentry Error Tracking ---
# Sign up at sentry.io and create a project
# Get DSN from: Settings > Projects > [Your Project] > Client Keys (DSN)
SENTRY_DSN=https://xxxxx@o123456.ingest.sentry.io/7654321
SENTRY_ENVIRONMENT=development
SENTRY_RELEASE=1.0.0
SENTRY_TRACES_SAMPLE_RATE=0.1  # 10% of transactions
SENTRY_DEBUG=false

# --- Slack Alerts ---
# Create webhook at: https://api.slack.com/messaging/webhooks
# Workspace > Apps > Incoming Webhooks > Add to Slack
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXX

# Optional: Separate webhooks for different severity levels
# SLACK_WEBHOOK_CRITICAL=https://hooks.slack.com/services/T00000000/B11111111/YYYYYYYYYYYYYYYYYYYY
# SLACK_WEBHOOK_WARNING=https://hooks.slack.com/services/T00000000/B22222222/ZZZZZZZZZZZZZZZZZZZZ

# --- Email Alerts (SMTP) ---
# Already configured above, additional alert-specific settings:
ALERT_EMAIL_FROM=alerts@yourcompany.com
ALERT_EMAIL_TO=ops@yourcompany.com,devops@yourcompany.com

# Optional: Severity-specific email recipients
# ALERT_EMAIL_CRITICAL=oncall@yourcompany.com,cto@yourcompany.com
# ALERT_EMAIL_WARNING=ops@yourcompany.com

# --- PagerDuty Integration (Optional) ---
# Create integration at: Service Directory > Your Service > Integrations
# PAGERDUTY_INTEGRATION_KEY=your-integration-key
# PAGERDUTY_SERVICE_ID=your-service-id

# --- Alert Configuration ---
ALERTING_ENABLED=true
ALERT_CHECK_INTERVAL=60000  # 60 seconds

# Alert thresholds (adjust based on your system)
ALERT_MEMORY_THRESHOLD=90  # Trigger at 90% memory usage
ALERT_ERROR_THRESHOLD=100  # Trigger at 100 errors per minute
ALERT_RESPONSE_TIME_THRESHOLD=2000  # Trigger at 2000ms (2 seconds)
ALERT_DB_POOL_THRESHOLD=19  # Trigger when 19/20 DB connections used
ALERT_CACHE_HIT_RATE_THRESHOLD=70  # Trigger when cache hit rate < 70%
ALERT_OVERDUE_ASSESSMENTS_THRESHOLD=10  # Trigger when > 10 assessments overdue

# --- Log Aggregation ---
LOG_AGGREGATION_ENABLED=true
LOG_AGGREGATION_BACKEND=elk  # Options: elk, datadog, cloudwatch, loki
LOG_FLUSH_INTERVAL=60000  # 60 seconds
LOG_BUFFER_SIZE=1000  # Max logs before forced flush

# Option 1: ELK Stack (Elasticsearch, Logstash, Kibana)
# ELASTICSEARCH_URL=http://localhost:9200
# ELASTICSEARCH_INDEX=grc-logs
# ELASTICSEARCH_USERNAME=elastic
# ELASTICSEARCH_PASSWORD=changeme

# Option 2: Datadog Logs
# Sign up at datadoghq.com and get API key from Organization Settings > API Keys
# DATADOG_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxx
# DATADOG_SITE=datadoghq.com  # or datadoghq.eu for EU region

# Option 3: AWS CloudWatch Logs
# AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=AKIAXXXXXXXXXXXXXXXX
# AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# CLOUDWATCH_LOG_GROUP=/grc/application
# CLOUDWATCH_LOG_STREAM=backend

# Option 4: Loki (Grafana)
# Start with: docker run -d --name=loki -p 3100:3100 grafana/loki:latest
# LOKI_URL=http://localhost:3100

# --- Business Metrics ---
BUSINESS_METRICS_ENABLED=true
BUSINESS_METRICS_INTERVAL=300000  # 5 minutes

# --- Performance Monitoring ---
PERFORMANCE_MONITORING_ENABLED=true
SLOW_REQUEST_THRESHOLD=2000  # Log requests slower than 2 seconds
SLOW_QUERY_THRESHOLD=100  # Log DB queries slower than 100ms
ERROR_FLUSH_INTERVAL=30000  # 30 seconds
ERROR_BUFFER_SIZE=100  # Max errors before forced flush

# --- Monitoring Dashboard ---
# Access monitoring dashboard at: http://localhost:4000/api/v1/monitoring/dashboard
# Prometheus metrics at: http://localhost:4000/metrics
# JSON metrics at: http://localhost:4000/metrics/json